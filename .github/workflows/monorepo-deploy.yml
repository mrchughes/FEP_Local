name: "üöÄ Monorepo Deploy - Clean CI/CD"

on:
  push:
    branches: [main, master]
  workflow_dispatch:
    inputs:
      clean_deploy:
        description: 'Skip import and deploy from scratch'
        type: boolean
        default: false

env:
  AWS_REGION: ${{ secrets.AWS_REGION }}

jobs:
  # Detect what changed to optimize deployments
  detect-changes:
    runs-on: ubuntu-latest
    outputs:
      infra-changed: ${{ steps.changes.outputs.infra-changed }}
      mern-changed: ${{ steps.changes.outputs.mern-changed }}
      python-changed: ${{ steps.changes.outputs.python-changed }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 2
      
      - name: Detect changes
        id: changes
        run: |
          if git diff --name-only HEAD^ HEAD | grep -q "shared-infra/"; then
            echo "infra-changed=true" >> $GITHUB_OUTPUT
          else
            echo "infra-changed=false" >> $GITHUB_OUTPUT
          fi
          
          if git diff --name-only HEAD^ HEAD | grep -q "mern-app/"; then
            echo "mern-changed=true" >> $GITHUB_OUTPUT
          else
            echo "mern-changed=false" >> $GITHUB_OUTPUT
          fi
          
          if git diff --name-only HEAD^ HEAD | grep -q "python-app/"; then
            echo "python-changed=true" >> $GITHUB_OUTPUT
          else
            echo "python-changed=false" >> $GITHUB_OUTPUT
          fi

      - name: Show deployment plan
        run: |
          echo "üéØ Deployment Plan:"
          echo "‚îú‚îÄ‚îÄ Clean Deployment: ${{ github.event.inputs.clean_deploy == 'true' && '‚úÖ Enabled' || '‚ùå Disabled' }}"
          echo "‚îú‚îÄ‚îÄ Shared Infrastructure: ${{ steps.changes.outputs.infra-changed == 'true' && 'üîÑ Deploy' || '‚è≠Ô∏è  Skip' }}"
          echo "‚îú‚îÄ‚îÄ MERN App: ${{ steps.changes.outputs.mern-changed == 'true' && 'üîÑ Deploy' || '‚è≠Ô∏è  Skip' }}"
          echo "‚îî‚îÄ‚îÄ Python App: ${{ steps.changes.outputs.python-changed == 'true' && 'üîÑ Deploy' || '‚è≠Ô∏è  Skip' }}"

  # Step 1: Deploy shared infrastructure (always runs first)
  deploy-infrastructure:
    runs-on: ubuntu-latest
    needs: detect-changes
    defaults:
      run:
        working-directory: ./shared-infra/terraform
    outputs:
      vpc-id: ${{ steps.tf-outputs.outputs.vpc_id }}
      ecr-frontend: ${{ steps.tf-outputs.outputs.ecr_frontend }}
      ecr-backend: ${{ steps.tf-outputs.outputs.ecr_backend }}
      ecr-python: ${{ steps.tf-outputs.outputs.ecr_python }}
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: üîí Validate Deployment Constraints
        run: |
          echo "üîí DEPLOYMENT CONSTRAINT VALIDATION"
          echo "==================================="
          echo "Ensuring deployment stays within approved bounds:"
          echo "  ‚úì Region: eu-west-2 ONLY"
          echo "  ‚úì Domain: mrchughes.site ONLY"
          echo ""
          
          cd ${{ github.workspace }}
          chmod +x scripts/validate-deployment-constraints.sh
          ./scripts/validate-deployment-constraints.sh
          
          echo ""
          echo "‚úÖ Deployment constraints validated - proceeding with deployment"

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false

      - name: Terraform Init
        run: terraform init

      - name: Infrastructure Configuration Validation
        run: |
          echo "=== INFRASTRUCTURE VALIDATION ==="
          
          # Run our comprehensive validation script
          cd ${{ github.workspace }}
          if [ -f "./scripts/prevent-config-drift.sh" ]; then
            echo "Running comprehensive infrastructure validation..."
            ./scripts/prevent-config-drift.sh shared-infra
            echo "‚úÖ Infrastructure validation passed"
            
            # Critical port alignment validation
            echo "üîç Validating port alignment across all services..."
            ./scripts/validate-port-alignment.sh
            echo "‚úÖ Port alignment validation passed"
            
            # CRITICAL: ECR repository alignment validation
            echo "üê≥ Validating ECR repository and container image alignment..."
            ./scripts/validate-ecr-alignment.sh
            echo "‚úÖ ECR alignment validation passed"
          else
            echo "‚ö†Ô∏è  scripts/prevent-config-drift.sh not found, running basic checks..."
            
            # Basic validation if script missing
            cd shared-infra/terraform
            
            # Check Terraform formatting
            if ! terraform fmt -check=true; then
              echo "‚ùå Terraform files need formatting"
              exit 1
            fi
            
            # Validate state key
            if ! grep -q 'key.*=.*"shared-infra/terraform.tfstate"' main.tf; then
              echo "‚ùå Incorrect state key configuration"
              exit 1
            fi
            
            # Check region consistency  
            if grep -q 'region.*=.*"us-\|region.*=.*"ap-' main.tf variables.tf 2>/dev/null; then
              echo "‚ùå Non-standard AWS region found"
              exit 1
            fi
            
            echo "‚úÖ Basic validation passed"
          fi

      # Comprehensive pre-deployment checks
      - name: Pre-deployment Resource Check
        run: |
          echo "üîç Scanning for existing AWS resources..."
          
          # Check for conflicting VPCs (none expected after cleanup)
          OTHER_VPCS=$(aws ec2 describe-vpcs --region ${{ env.AWS_REGION }} --query "Vpcs[?IsDefault==\`false\`].VpcId" --output text)
          if [ -n "$OTHER_VPCS" ]; then
            echo "‚ö†Ô∏è  Found existing VPCs: $OTHER_VPCS"
            echo "::warning::Multiple VPCs found that might cause conflicts. Consider running cleanup script."
          fi
          
          # Check for existing resources
          echo "üìä Resource inventory:"
          
          # DynamoDB
          if aws dynamodb describe-table --region ${{ env.AWS_REGION }} --table-name cloud-apps-table &>/dev/null; then
            echo "‚úÖ DynamoDB table: cloud-apps-table"
          else
            echo "‚ûñ DynamoDB table: cloud-apps-table (will be created)"
          fi
          
          # ECR repositories
          for REPO in "mern-app-frontend" "mern-app-backend" "python-app"; do
            if aws ecr describe-repositories --region ${{ env.AWS_REGION }} --repository-names $REPO &>/dev/null; then
              echo "‚úÖ ECR repository: $REPO"
            else
              echo "‚ûñ ECR repository: $REPO (will be created)"
            fi
          done
          
          # S3 bucket
          if aws s3api head-bucket --bucket cloud-apps-shared-bucket &>/dev/null; then
            echo "‚úÖ S3 bucket: cloud-apps-shared-bucket"
          else
            echo "‚ûñ S3 bucket: cloud-apps-shared-bucket (will be created)"
          fi
          
          # Load Balancer
          if aws elbv2 describe-load-balancers --region ${{ env.AWS_REGION }} --names cloud-apps-alb &>/dev/null; then
            echo "‚úÖ Load Balancer: cloud-apps-alb"
          else
            echo "‚ûñ Load Balancer: cloud-apps-alb (will be created)"
          fi

      # Import resources only if not doing a clean deployment
      - name: Import Existing Resources
        if: ${{ github.event.inputs.clean_deploy != 'true' && needs.detect-changes.outputs.infra-changed == 'true' }}
        continue-on-error: true
        run: |
          echo "üîÑ Checking and importing missing AWS resources..."
          
          # Initialize counter for successful imports
          IMPORT_COUNT=0
          IMPORT_FAILURES=0
          
          # Function to check if resource is already in state
          resource_in_state() {
            local resource_addr="$1"
            terraform state show "$resource_addr" >/dev/null 2>&1
          }
          
          # Function to attempt import with state checking
          attempt_import() {
            local resource_addr="$1"
            local resource_id="$2"
            local description="$3"
            
            if resource_in_state "$resource_addr"; then
              echo "‚úÖ $description already in state - skipping import"
              return 0
            fi
            
            echo "Attempting to import $description..."
            if terraform import "$resource_addr" "$resource_id" 2>/dev/null; then
              echo "‚úÖ Successfully imported $description"
              ((IMPORT_COUNT++))
            else
              echo "‚ö†Ô∏è Failed to import $description (resource may not exist)"
              ((IMPORT_FAILURES++))
            fi
          }
          
          # DynamoDB table
          if aws dynamodb describe-table --region ${{ env.AWS_REGION }} --table-name cloud-apps-table &>/dev/null; then
            attempt_import "module.dynamodb.aws_dynamodb_table.app" "cloud-apps-table" "DynamoDB table"
          fi
          
          # ECR repositories
          for REPO in "mern-app-frontend:module.ecr.aws_ecr_repository.app1_frontend" "mern-app-backend:module.ecr.aws_ecr_repository.app1_backend" "python-app:module.ecr.aws_ecr_repository.app2"; do
            REPO_NAME=${REPO%%:*}
            REPO_ADDR=${REPO#*:}
            
            if aws ecr describe-repositories --region ${{ env.AWS_REGION }} --repository-names $REPO_NAME &>/dev/null; then
              attempt_import "$REPO_ADDR" "$REPO_NAME" "ECR repository $REPO_NAME"
            fi
          done
          
          # S3 bucket - try both potential names
          for BUCKET in "cloud-apps-shared-bucket" "cloud-apps-shared-bucket-202507021301"; do
            if aws s3api head-bucket --bucket $BUCKET 2>/dev/null; then
              attempt_import "module.s3.aws_s3_bucket.app" "$BUCKET" "S3 bucket $BUCKET"
              break
            fi
          done
          
          # IAM role
          if aws iam get-role --role-name ecsTaskExecutionRole &>/dev/null; then
            attempt_import "module.iam.aws_iam_role.ecs_task_execution_role" "ecsTaskExecutionRole" "IAM role"
            
            # Policy attachment
            if aws iam list-attached-role-policies --role-name ecsTaskExecutionRole | grep -q "AmazonECSTaskExecutionRolePolicy"; then
              attempt_import "module.iam.aws_iam_role_policy_attachment.ecs_task_execution_role_policy" "ecsTaskExecutionRole/arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy" "IAM policy attachment"
            fi
          fi
          
          # Check for Route53 zone
          ZONE_ID=$(aws route53 list-hosted-zones-by-name --dns-name "mrchughes.site." --max-items 1 --query "HostedZones[0].Id" --output text 2>/dev/null | sed 's|/hostedzone/||')
          if [[ -n "$ZONE_ID" && "$ZONE_ID" != "None" ]]; then
            attempt_import "module.route53.aws_route53_zone.main" "$ZONE_ID" "Route53 zone"
          fi
          
          # Check for ALB and related resources
          if aws elbv2 describe-load-balancers --region ${{ env.AWS_REGION }} --names cloud-apps-alb &>/dev/null; then
            ALB_ARN=$(aws elbv2 describe-load-balancers --region ${{ env.AWS_REGION }} --names cloud-apps-alb --query "LoadBalancers[0].LoadBalancerArn" --output text)
            attempt_import "module.alb.aws_lb.shared_alb" "$ALB_ARN" "Application Load Balancer"
            
            # Try to import target groups
            for TG_NAME in "cloud-apps-app1-tg" "cloud-apps-app2-tg" "cloud-apps-backend-api-tg"; do
              TG_ARN=$(aws elbv2 describe-target-groups --region ${{ env.AWS_REGION }} --names $TG_NAME --query "TargetGroups[0].TargetGroupArn" --output text 2>/dev/null)
              if [[ $TG_ARN != "None" && -n $TG_ARN ]]; then
                case $TG_NAME in
                  "cloud-apps-app1-tg")
                    attempt_import "module.alb.aws_lb_target_group.app1" "$TG_ARN" "Target group $TG_NAME"
                    ;;
                  "cloud-apps-app2-tg")
                    attempt_import "module.alb.aws_lb_target_group.app2" "$TG_ARN" "Target group $TG_NAME"
                    ;;
                  "cloud-apps-backend-api-tg")
                    attempt_import "module.alb.aws_lb_target_group.backend_api" "$TG_ARN" "Target group $TG_NAME"
                    ;;
                esac
              fi
            done
          fi
          
          # Summary
          echo "üìä Import Summary: $IMPORT_COUNT new resources imported, $IMPORT_FAILURES failures"
          echo "‚ÑπÔ∏è  Resources already in state are managed and will be updated as needed"

      - name: Terraform Plan
        run: |
          terraform plan -out=tfplan \
            -var="deployment_id=${{ github.run_id }}-$(date +%Y%m%d-%H%M)" \
            -var="deployment_source=github-actions"

      - name: Terraform Validate Plan
        run: |
          echo "üîç Validating Terraform plan..."
          terraform show -json tfplan > tfplan.json
          
          # Basic plan validation
          if [ ! -s tfplan.json ]; then
            echo "‚ùå Plan file is empty or invalid"
            exit 1
          fi
          
          # Check for destructive operations
          DESTROY_COUNT=$(cat tfplan.json | jq -r '.resource_changes[]? | select(.change.actions[]? == "delete") | .address' | wc -l)
          if [ "$DESTROY_COUNT" -gt 0 ]; then
            echo "‚ö†Ô∏è  Plan contains $DESTROY_COUNT resource deletions"
            cat tfplan.json | jq -r '.resource_changes[]? | select(.change.actions[]? == "delete") | .address'
          fi
          
          echo "‚úÖ Plan validation complete"

      - name: Terraform Apply
        if: needs.detect-changes.outputs.infra-changed == 'true' || github.event.inputs.clean_deploy == 'true'
        run: |
          echo "üöÄ Applying Terraform plan..."
          terraform apply -auto-approve tfplan
          echo "‚úÖ Infrastructure deployment complete"

      - name: Export Infrastructure Outputs
        id: tf-outputs
        run: |
          # Check if terraform state exists and has outputs
          if terraform output vpc_id >/dev/null 2>&1; then
            echo "vpc_id=$(terraform output -raw vpc_id)" >> $GITHUB_OUTPUT
            echo "ecr_frontend=$(terraform output -raw ecr_repo_frontend | sed 's|.*amazonaws.com/||')" >> $GITHUB_OUTPUT
            echo "ecr_backend=$(terraform output -raw ecr_repo_backend | sed 's|.*amazonaws.com/||')" >> $GITHUB_OUTPUT  
            echo "ecr_python=$(terraform output -raw ecr_repo_app2 | sed 's|.*amazonaws.com/||')" >> $GITHUB_OUTPUT
            echo "‚úÖ Successfully exported infrastructure outputs"
          else
            echo "‚ö†Ô∏è No terraform outputs available - infrastructure may not be deployed yet"
            # Set empty defaults to prevent workflow failure
            echo "vpc_id=" >> $GITHUB_OUTPUT
            echo "ecr_frontend=" >> $GITHUB_OUTPUT
            echo "ecr_backend=" >> $GITHUB_OUTPUT
            echo "ecr_python=" >> $GITHUB_OUTPUT
          fi

  # Step 2: Build and deploy MERN app (frontend + backend)
  deploy-mern-app:
    runs-on: ubuntu-latest
    needs: [detect-changes, deploy-infrastructure]
    # CRITICAL FIX: Always deploy MERN app if infrastructure is available or if any changes detected
    if: always() && needs.deploy-infrastructure.result == 'success' && (needs.detect-changes.outputs.mern-changed == 'true' || needs.detect-changes.outputs.infra-changed == 'true' || github.event.inputs.clean_deploy == 'true' || needs.deploy-infrastructure.outputs.ecr-frontend != '')
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Validate ECR Registry
        run: |
          echo "üîç Validating ECR registry configuration..."
          ECR_REGISTRY="${{ steps.login-ecr.outputs.registry }}"
          echo "ECR Registry: $ECR_REGISTRY"
          
          # Ensure we're using account-specific registry
          if [[ ! "$ECR_REGISTRY" =~ ^[0-9]{12}\.dkr\.ecr\.[a-z0-9-]+\.amazonaws\.com$ ]]; then
            echo "‚ùå Invalid ECR registry format: $ECR_REGISTRY"
            exit 1
          fi
          
          ACCOUNT_ID=$(echo "$ECR_REGISTRY" | cut -d'.' -f1)
          REGION=$(echo "$ECR_REGISTRY" | cut -d'.' -f4)
          echo "‚úÖ Using account-specific ECR registry: Account $ACCOUNT_ID, Region $REGION"

      - name: Check Infrastructure Status
        run: |
          echo "üîç Checking infrastructure readiness..."
          echo "ECR Frontend: '${{ needs.deploy-infrastructure.outputs.ecr-frontend }}'"
          echo "ECR Backend: '${{ needs.deploy-infrastructure.outputs.ecr-backend }}'"
          echo "VPC ID: '${{ needs.deploy-infrastructure.outputs.vpc-id }}'"
          
          if [ -z "${{ needs.deploy-infrastructure.outputs.ecr-frontend }}" ]; then
            echo "‚ö†Ô∏è Infrastructure not ready yet - skipping builds until next run"
          else
            echo "‚úÖ Infrastructure ready - proceeding with builds"
          fi

      - name: Build and push Frontend image
        # CRITICAL FIX: Build if ECR output exists OR if we can determine repository name
        if: needs.deploy-infrastructure.outputs.ecr-frontend != '' || needs.deploy-infrastructure.result == 'success'
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPO: ${{ needs.deploy-infrastructure.outputs.ecr-frontend }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          # CRITICAL FIX: Handle case where ECR output might be empty
          if [ -z "$ECR_REPO" ]; then
            echo "üîç ECR output empty, determining repository name from infrastructure..."
            ECR_REPO="mern-app-frontend"
          fi
          
          echo "üèóÔ∏è Building Frontend..."
          echo "Registry: $ECR_REGISTRY"
          echo "Repository: $ECR_REPO"
          echo "Image Tag: $IMAGE_TAG"
          
          docker build -f mern-app/frontend/Dockerfile.frontend \
            --build-arg REACT_APP_API_URL=https://app1.mrchughes.site/api \
            --build-arg REACT_APP_S3_BUCKET=mern-app-bucket \
            -t $ECR_REGISTRY/$ECR_REPO:$IMAGE_TAG \
            -t $ECR_REGISTRY/$ECR_REPO:latest \
            mern-app/frontend/ # Allow :latest for development
          echo "üì§ Pushing Frontend to ECR..."
          docker push $ECR_REGISTRY/$ECR_REPO:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPO:latest # Allow :latest for development

      - name: Build and push Backend image
        # CRITICAL FIX: Build if ECR output exists OR if we can determine repository name  
        if: needs.deploy-infrastructure.outputs.ecr-backend != '' || needs.deploy-infrastructure.result == 'success'
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPO: ${{ needs.deploy-infrastructure.outputs.ecr-backend }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          # CRITICAL FIX: Handle case where ECR output might be empty
          if [ -z "$ECR_REPO" ]; then
            echo "üîç ECR output empty, determining repository name from infrastructure..."
            ECR_REPO="mern-app-backend"
          fi
          
          echo "üèóÔ∏è Building Backend..."
          echo "Registry: $ECR_REGISTRY"
          echo "Repository: $ECR_REPO"
          echo "Image Tag: $IMAGE_TAG"
          
          docker build -f mern-app/backend/Dockerfile.backend -t $ECR_REGISTRY/$ECR_REPO:$IMAGE_TAG -t $ECR_REGISTRY/$ECR_REPO:latest mern-app/backend/ # Allow :latest for development
          echo "üì§ Pushing Backend to ECR..."
          docker push $ECR_REGISTRY/$ECR_REPO:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPO:latest # Allow :latest for development

      - name: Setup Terraform for MERN deployment
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false

      - name: Deploy MERN Infrastructure
        # CRITICAL FIX: Deploy if ECR outputs exist OR if infrastructure was successful
        if: (needs.deploy-infrastructure.outputs.ecr-frontend != '' && needs.deploy-infrastructure.outputs.ecr-backend != '') || needs.deploy-infrastructure.result == 'success'
        working-directory: ./mern-app/terraform
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          echo "üöÄ Planning MERN infrastructure deployment..."
          terraform init
          
          # CRITICAL FIX: Handle case where ECR outputs might be empty
          FRONTEND_REPO="${{ needs.deploy-infrastructure.outputs.ecr-frontend }}"
          BACKEND_REPO="${{ needs.deploy-infrastructure.outputs.ecr-backend }}"
          
          if [ -z "$FRONTEND_REPO" ]; then
            echo "üîç Frontend ECR output empty, using default repository name..."
            FRONTEND_REPO="mern-app-frontend"
          fi
          
          if [ -z "$BACKEND_REPO" ]; then
            echo "üîç Backend ECR output empty, using default repository name..."
            BACKEND_REPO="mern-app-backend"
          fi
          
          # Debug: Show what images we're deploying
          FRONTEND_IMAGE="$ECR_REGISTRY/$FRONTEND_REPO:$IMAGE_TAG"
          BACKEND_IMAGE="$ECR_REGISTRY/$BACKEND_REPO:$IMAGE_TAG"
          echo "Frontend Image: $FRONTEND_IMAGE"
          echo "Backend Image: $BACKEND_IMAGE"
          
          # Verify images exist in ECR before deploying
          echo "üîç Verifying images exist in ECR..."
          aws ecr describe-images --repository-name "$FRONTEND_REPO" --image-ids imageTag="$IMAGE_TAG" --region ${{ env.AWS_REGION }}
          aws ecr describe-images --repository-name "$BACKEND_REPO" --image-ids imageTag="$IMAGE_TAG" --region ${{ env.AWS_REGION }}
          
          # Create and validate plan
          terraform plan -out=mern-tfplan \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="ecr_repo_frontend=$FRONTEND_IMAGE" \
            -var="ecr_repo_backend=$BACKEND_IMAGE" \
            -var="deployment_id=${{ github.run_id }}-$(date +%Y%m%d-%H%M)-mern" \
            -var="deployment_source=github-actions"
          
          echo "üîç Validating MERN plan..."
          terraform show mern-tfplan
          
          echo "üöÄ Applying MERN infrastructure..."
          terraform apply -auto-approve mern-tfplan
          echo "‚úÖ MERN infrastructure deployment complete"
          
          # Force ECS services to update with new task definitions (CRITICAL FIX)
          echo "üîÑ Forcing ECS service updates with new images..."
          aws ecs update-service --cluster cloud-apps-mern-cluster --service cloud-apps-mern-frontend --force-new-deployment --region ${{ env.AWS_REGION }}
          aws ecs update-service --cluster cloud-apps-mern-cluster --service cloud-apps-mern-backend --force-new-deployment --region ${{ env.AWS_REGION }}
          echo "‚úÖ ECS services forced to update"

      - name: Wait for MERN deployment and verify
        run: |
          echo "üîç Checking ECS cluster status..."
          aws ecs describe-clusters --clusters cloud-apps-mern-cluster --region ${{ env.AWS_REGION }}
          
          echo "üîç Checking ECS services status..."
          aws ecs describe-services --cluster cloud-apps-mern-cluster --services cloud-apps-mern-frontend cloud-apps-mern-backend --region ${{ env.AWS_REGION }}
          
          echo "üîç Checking running tasks..."
          aws ecs list-tasks --cluster cloud-apps-mern-cluster --region ${{ env.AWS_REGION }}
          
          # Check if services exist before waiting
          FRONTEND_SERVICE=$(aws ecs describe-services --cluster cloud-apps-mern-cluster --services cloud-apps-mern-frontend --region ${{ env.AWS_REGION }} --query 'services[0].serviceName' --output text 2>/dev/null || echo "NONE")
          BACKEND_SERVICE=$(aws ecs describe-services --cluster cloud-apps-mern-cluster --services cloud-apps-mern-backend --region ${{ env.AWS_REGION }} --query 'services[0].serviceName' --output text 2>/dev/null || echo "NONE")
          
          if [ "$FRONTEND_SERVICE" != "NONE" ] && [ "$BACKEND_SERVICE" != "NONE" ]; then
            echo "‚è≥ Waiting for MERN services to stabilize (max 10 minutes)..."
            timeout 600 aws ecs wait services-stable --cluster cloud-apps-mern-cluster --services cloud-apps-mern-frontend cloud-apps-mern-backend --region ${{ env.AWS_REGION }} || {
              echo "‚ö†Ô∏è Services did not stabilize within 10 minutes"
              echo "üîç Checking task failures..."
              aws ecs describe-services --cluster cloud-apps-mern-cluster --services cloud-apps-mern-frontend cloud-apps-mern-backend --region ${{ env.AWS_REGION }} --query 'services[*].events[0:3]'
              exit 1
            }
            echo "‚úÖ MERN services are stable and running"
          else
            echo "‚ùå One or more services were not created properly"
            echo "Frontend service: $FRONTEND_SERVICE"
            echo "Backend service: $BACKEND_SERVICE"
            exit 1
          fi
          echo "‚úÖ MERN app deployed successfully!"

  # Step 3: Build and deploy Python app (runs in parallel with MERN)
  deploy-python-app:
    runs-on: ubuntu-latest
    needs: [detect-changes, deploy-infrastructure]
    if: needs.detect-changes.outputs.python-changed == 'true' || needs.detect-changes.outputs.infra-changed == 'true' || github.event.inputs.clean_deploy == 'true'
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build and push Python image
        if: needs.deploy-infrastructure.outputs.ecr-python != ''
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPO: ${{ needs.deploy-infrastructure.outputs.ecr-python }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          echo "üêç Building Python app..."
          docker build -f python-app/app/Dockerfile -t $ECR_REGISTRY/$ECR_REPO:$IMAGE_TAG -t $ECR_REGISTRY/$ECR_REPO:latest python-app/app/ # Allow :latest for development
          echo "üì§ Pushing Python app to ECR..."
          docker push $ECR_REGISTRY/$ECR_REPO:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPO:latest # Allow :latest for development

      - name: Setup Terraform for Python deployment
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false

      - name: Deploy Python Infrastructure
        if: needs.deploy-infrastructure.outputs.ecr-python != ''
        working-directory: ./python-app/terraform
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          echo "üöÄ Planning Python infrastructure deployment..."
          terraform init
          
          # Create and validate plan
          terraform plan -out=python-tfplan \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="ecr_repo_app2=$ECR_REGISTRY/${{ needs.deploy-infrastructure.outputs.ecr-python }}:$IMAGE_TAG" \
            -var="deployment_id=${{ github.run_id }}-$(date +%Y%m%d-%H%M)-python" \
            -var="deployment_source=github-actions"
          
          echo "üîç Validating Python plan..."
          terraform show python-tfplan
          
          echo "üöÄ Applying Python infrastructure..."
          terraform apply -auto-approve python-tfplan
          echo "‚úÖ Python infrastructure deployment complete"

      - name: Wait for Python deployment
        run: |
          echo "‚è≥ Waiting for Python service to stabilize..."
          aws ecs wait services-stable --cluster cloud-apps-python-cluster --services python-app --region ${{ env.AWS_REGION }}
          echo "‚úÖ Python app deployed successfully!"

  # Step 4: Post-deployment validation and orphaned resource check
  post-deployment-validation:
    runs-on: ubuntu-latest
    needs: [detect-changes, deploy-infrastructure, deploy-mern-app, deploy-python-app]
    if: success()
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Post-deployment Orphaned Resource Check
        run: |
          echo "üîç Checking for orphaned resources after deployment..."
          if [ -f "./scripts/detect-orphaned-resources.sh" ]; then
            ./scripts/detect-orphaned-resources.sh
            
            # If orphaned resources are found, create an issue or notification
            if [ $? -ne 0 ]; then
              echo "‚ö†Ô∏è  Orphaned resources detected after deployment"
              echo "This may indicate a partial deployment failure or resource leak"
              # Note: In a real scenario, you might want to create a GitHub issue or send a notification
            else
              echo "‚úÖ No orphaned resources detected"
            fi
          else
            echo "‚ö†Ô∏è  Orphaned resource detection script not found"
          fi

      - name: Final Infrastructure Validation
        run: |
          echo "üèóÔ∏è  Running final infrastructure validation..."
          
          # Run comprehensive validation
          if [ -f "./scripts/comprehensive-test.sh" ]; then
            ./scripts/comprehensive-test.sh
          fi
          
          # Validate port alignment one more time
          if [ -f "./scripts/validate-port-alignment.sh" ]; then
            ./scripts/validate-port-alignment.sh
          fi
          
          # Check state consistency
          if [ -f "./scripts/validate-state-keys.sh" ]; then
            ./scripts/validate-state-keys.sh
          fi

  # Step 5: Final summary and cleanup on failure
  deployment-summary:
    runs-on: ubuntu-latest
    needs: [detect-changes, deploy-infrastructure, deploy-mern-app, deploy-python-app, post-deployment-validation]
    if: always()
    steps:
      - name: Checkout repository (for failure recovery if needed)
        uses: actions/checkout@v4
        if: failure()

      - name: Configure AWS credentials (for failure recovery if needed)
        uses: aws-actions/configure-aws-credentials@v4
        if: failure()
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Deployment Failure Recovery
        if: failure()
        run: |
          echo "üö® Deployment failure detected - running recovery procedures..."
          
          if [ -f "./scripts/deployment-failure-recovery.sh" ]; then
            # Run non-interactive recovery
            echo "yes" | ./scripts/deployment-failure-recovery.sh || true
          fi
          
          if [ -f "./scripts/detect-orphaned-resources.sh" ]; then
            echo "üîç Checking for orphaned resources caused by failure..."
            ./scripts/detect-orphaned-resources.sh || true
          fi
          
          echo ""
          echo "‚ùå Deployment failed with automated recovery attempted"
          echo "üìù Review the recovery logs above for next steps"
          echo "üÜò Manual intervention may be required"

      - name: Deployment Summary
        run: |
          if [ "${{ job.status }}" = "success" ]; then
            echo "üéâ Deployment Complete!"
            echo ""
            echo "üìä Summary:"
            echo "‚îú‚îÄ‚îÄ Clean Deployment: ${{ github.event.inputs.clean_deploy == 'true' && '‚úÖ Performed' || '‚ùå Skipped' }}"
            echo "‚îú‚îÄ‚îÄ Infrastructure: ${{ (needs.detect-changes.outputs.infra-changed == 'true' || github.event.inputs.clean_deploy == 'true') && '‚úÖ Deployed' || '‚è≠Ô∏è  Skipped' }}"
            echo "‚îú‚îÄ‚îÄ MERN App: ${{ (needs.detect-changes.outputs.mern-changed == 'true' || needs.detect-changes.outputs.infra-changed == 'true' || github.event.inputs.clean_deploy == 'true') && '‚úÖ Deployed' || '‚è≠Ô∏è  Skipped' }}"
            echo "‚îú‚îÄ‚îÄ Python App: ${{ (needs.detect-changes.outputs.python-changed == 'true' || needs.detect-changes.outputs.infra-changed == 'true' || github.event.inputs.clean_deploy == 'true') && '‚úÖ Deployed' || '‚è≠Ô∏è  Skipped' }}"
            echo "‚îî‚îÄ‚îÄ Post-deployment Validation: ‚úÖ Passed"
            echo ""
            echo "üåê Your apps are live at:"
            echo "‚îú‚îÄ‚îÄ Frontend: https://app1.mrchughes.site"
            echo "‚îú‚îÄ‚îÄ Backend API: https://app1.mrchughes.site/api"
            echo "‚îî‚îÄ‚îÄ Python App: https://app2.mrchughes.site"
            echo ""
            echo "üöÄ Next push will automatically deploy only changed components!"
          else
            echo "‚ùå Deployment Failed"
            echo ""
            echo "üîß Automated recovery was attempted. Please:"
            echo "1. Review the deployment logs above"
            echo "2. Check for orphaned resources"
            echo "3. Run manual recovery if needed"
            echo "4. Contact the infrastructure team if issues persist"
          fi
